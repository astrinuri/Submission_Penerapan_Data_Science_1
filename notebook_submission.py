# -*- coding: utf-8 -*-
"""Notebook Submission.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15JkvwAYfwPCPxEZKVL1MwL-DpJkA8H8M

# **Proyek Akhir: Menyelesaikan Permasalahan Perusahaan Edutech**

- Nama : Astri Nur Innayah
- Email : skripsiastri1@gmail.com
- ID Dicoding : A406XBM074

# **Persiapan**

## **Menyiapkan Library yang dibutuhkan**

Bagian ini berguna untuk menginstall dan mengimport semua library yang dibutuhkan
"""

import gdown
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import shap
import joblib

from sklearn.preprocessing import LabelEncoder, MinMaxScaler
from sklearn.model_selection import train_test_split, GridSearchCV

from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from xgboost import XGBClassifier

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.metrics import confusion_matrix, classification_report
from scipy.stats import chi2_contingency
from sklearn.feature_selection import RFE
from imblearn.over_sampling import SMOTE

from google.colab import files

"""## **Menyiapkan Data yang akan digunakan**

Bagian ini berguna untuk mengimport data yang akan digunakan dalam pembangunan model
"""

# https://docs.google.com/spreadsheets/d/1kct_04tV9dBTMRT1DldpI0hDXcWg6I3AVW5TAZb7I9o/edit?gid=665015379#gid=665015379
file_id = '1kct_04tV9dBTMRT1DldpI0hDXcWg6I3AVW5TAZb7I9o'
url = f'https://drive.google.com/uc?id={file_id}'
output = 'Dataset.xlsx'

gdown.download(url, output, quiet=False)

df = pd.read_excel('Dataset.xlsx')
df

"""## **Data Preparation**"""

df.info()

"""Data ini berisi rincian demografi, metrik yang berkaitan dengan pekerjaan, dan status pengunduran diri (attrition).

* **EmployeeId** - Identifikasi Karyawan
* **Attrition** - Apakah karyawan mengundurkan diri? (0=tidak, 1=ya)
* **Age** - Usia karyawan
* **BusinessTravel** - Komitmen perjalanan untuk pekerjaan
* **DailyRate** - Gaji per hari
* **Department** - Departemen tempat karyawan bekerja
* **DistanceFromHome** - Jarak dari rumah ke tempat kerja (dalam km)
* **Education** - 1-Di bawah perguruan tinggi, 2-Perguruan tinggi, 3-Sarjana, 4-Magister, 5-Doctor
* **EducationField** - Bidang Pendidikan
* **EmployeeCount**
* **EnvironmentSatisfaction** - 1-Rendah, 2-Sedang, 3-Tinggi, 4-Sangat Tinggi
* **Gender** - Jenis kelamin karyawan
* **HourlyRate** - Gaji per jam
* **JobInvolvement** - 1-Rendah, 2-Sedang, 3-Tinggi, 4-Sangat Tinggi
* **JobLevel** - Tingkat pekerjaan (1 hingga 5)
* **JobRole** - Peran pekerjaan
* **JobSatisfaction** - 1-Rendah, 2-Sedang, 3-Tinggi, 4-Sangat Tinggi
* **MaritalStatus** - Status perkawinan
* **MonthlyIncome** - Gaji bulanan
* **MonthlyRate** - Tarif bulanan
* **NumCompaniesWorked** - Jumlah perusahaan yang pernah bekerja
* **Over18** - Apakah karyawan berusia lebih dari 18 tahun?
* **OverTime** - Apakah karyawan bekerja lembur?
* **PercentSalaryHike** - Persentase kenaikan gaji tahun lalu
* **PerformanceRating** - 1-Rendah, 2-Baik, 3-Sangat Baik, 4-Terbuka
* **RelationshipSatisfaction** - 1-Rendah, 2-Sedang, 3-Tinggi, 4-Sangat Tinggi
* **StandardHours** - Jam kerja standar
* **StockOptionLevel** - Tingkat Opsi Saham
* **TotalWorkingYears** - Total tahun bekerja
* **TrainingTimesLastYear** - Jumlah pelatihan yang diikuti tahun lalu
* **WorkLifeBalance** - 1-Rendah, 2-Baik, 3-Sangat Baik, 4-Terbuka
* **YearsAtCompany** - Tahun bekerja di perusahaan
* **YearsInCurrentRole** - Tahun di peran saat ini
* **YearsSinceLastPromotion** - Tahun sejak promosi terakhir
* **YearsWithCurrManager** - Tahun bersama manajer saat ini

### **Cek nilai unik untuk tiap variabel kategorik**

Bagian ini untuk melihat kategori setiap variabel kategorik
"""

for feature in df.select_dtypes(include='object'):
    print(feature)
    print(df[feature].unique(), '\n')

"""### **Melihat Statistik Deskriptif untuk semua variabel**"""

df.describe()

df.describe(include='object')

"""Berdasarkan analisis statistik deskriptif, semua karyawan berusia di atas 18 tahun, yang dapat dilihat pada fitur unik `Over18` yang hanya memiliki 1 data, yaitu `Y`. Selain itu, fitur `EmployeeCount` juga hanya memiliki 1 nilai unik. Oleh karena itu, kita dapat mengeliminasi kedua fitur ini karena tidak memiliki pengaruh besar terhadap masalah bisnis.

Berdasarkan analisis statistik deskriptif, semua karyawan berusia di atas 18 tahun, yang dapat dilihat pada fitur unik `Over18` yang hanya memiliki 1 data, yaitu `Y`. Selain itu, fitur `EmployeeCount` juga hanya memiliki 1 nilai unik. Oleh karena itu, kita dapat mengeliminasi kedua fitur ini karena tidak memiliki pengaruh besar terhadap masalah bisnis.
"""

df = df.drop(['Over18', 'EmployeeCount'], axis=1)
df

"""### **Penanganan Missing Value dan Data Duplikat**"""

df.isnull().sum()

"""Terlihat bahwa dataset memiliki beberapa nilai yang hilang pada fitur `Attrition`, yang merupakan fitur utama dalam masalah bisnis yang akan diselesaikan, kita perlu menghapus data dengan nilai yang hilang tersebut.

"""

df.dropna(inplace=True)
df.isnull().sum()

"""Selanjutnya dilakukan pengecekkan duplikasi data"""

df.duplicated().sum()

"""Hasilnya, tidak terdapat data yang duplikat

### **Decoding Variabel Kategorik**

Decoding Ordinal untuk fitur-fitur berikut  :

* **Education**:

  * 1: Below College
  * 2: College
  * 3: Bachelor
  * 4: Master
  * 5: Doctor

* **EnvironmentSatisfaction**:

  * 1: Low
  * 2: Medium
  * 3: High
  * 4: Very High

* **JobInvolvement**:

  * 1: Low
  * 2: Medium
  * 3: High
  * 4: Very High

* **JobSatisfaction**:

  * 1: Low
  * 2: Medium
  * 3: High
  * 4: Very High

* **PerformanceRating**:

  * 1: Low
  * 2: Good
  * 3: Excellent
  * 4: Outstanding

* **RelationshipSatisfaction**:

  * 1: Low
  * 2: Medium
  * 3: High
  * 4: Very High

* **WorkLifeBalance**:

  * 1: Low
  * 2: Good
  * 3: Excellent
  * 4: Outstanding
"""

def ordinal_decoding(df, feature):
    """
    Convert encoded feature in a DataFrame to corresponding categorical labels

    Parameters
        df (pandas.DataFrame) : The DataFrame with feature(s) to be converted
        feature (str or list of str) : The feature name(s) to convert

    Returns
        pandas.DataFrame : The DataFrame with feature(s) as categorical labels
    """

    if feature == 'Attrition':
        category = {0: 'No', 1: 'Yes'}
        df[feature] = df[feature].map(category)
    elif feature == 'Education':
        category = {1: 'Below College', 2: 'College', 3: 'Bachelor',
                    4: 'Master', 5: 'Doctor'}
        df[feature] = df[feature].map(category)
    elif feature in ['WorkLifeBalance', 'PerformanceRating']:
        category = {1: 'Low', 2: 'Good', 3: 'Excellent', 4: 'Outstanding'}
        df[feature] = df[feature].map(category)
    else:
        category = {1: 'Low', 2: 'Medium', 3: 'High', 4: 'Very High'}
        for f in feature:
            df[f] = df[f].map(category)

    return df

df = ordinal_decoding(df, 'Attrition')
df = ordinal_decoding(df, 'Education')
df = ordinal_decoding(df, ['EnvironmentSatisfaction', 'JobInvolvement',
                           'JobSatisfaction', 'RelationshipSatisfaction'])
df = ordinal_decoding(df, ['PerformanceRating', 'WorkLifeBalance'])

df

"""# **Data Understanding**

Melihat statistik deskriptif untuk semua variabel
"""

df.describe(include='all')

"""## **Analisis Distribusi pada kelas target**"""

# Distribusi variabel target (Attrition)
attrition_counts = df['Attrition'].value_counts()
attrition_counts

attrition_percentage = df['Attrition'].value_counts(normalize=True) * 100
attrition_percentage

"""**Distribusi Target (`Attrition`)**
- No (Tidak Keluar): 83.08%
- Yes (Keluar): 16.92%

  Artinya, sebagian besar karyawan tidak keluar, tetapi `Attrition` tetap signifikan pada **16.92%** karyawan.

## **Analisis Fitur Numerik**
"""

numerical, categorical = [], []

for feature in df.columns:
    if not df[feature].dtype == 'object':
        numerical.append(feature)
    else:
        categorical.append(feature)

numerical_description = df[numerical].describe()
numerical_description

"""**Deskripsi Kolom Numerik**
- `Age`: Rata-rata usia adalah 37 tahun.
- `DistanceFromHome`: Sebagian besar karyawan tinggal dekat dengan kantor (jarak rata-rata 9 km).
- `YearsAtCompany`: Sebagian besar karyawan bekerja di perusahaan selama 5-9 tahun.
"""

df[numerical].hist(bins=15, figsize=(20, 18))
plt.show()

"""Berdasarkan grafik histogram di atas, sebagian besar fitur numerik menunjukkan distribusi yang condong ke kanan (right-skewed). Fitur-fitur tersebut antara lain `DistanceFromHome`, `MonthlyIncome`, `NumCompaniesWorked`, `PercentSalaryHike`, `TotalWorkingYears`, `YearsAtCompany`, `YearsInCurrentRole`, `YearsSinceLastPromotion`, dan `YearsWithCurrManager`. Hal ini mengindikasikan bahwa sebagian besar nilai berada pada kisaran rendah, sementara hanya sedikit data yang memiliki nilai tinggi. Sementara itu, fitur seperti `Age` dan `TrainingTimesLastYear` memiliki distribusi yang lebih simetris atau mendekati normal, mencerminkan sebaran nilai yang relatif seimbang di sekitar rata-rata. Beberapa fitur lain seperti `EmployeeID`, `DailyRate`, `HourlyRate`, dan `MonthlyRate` tampak tersebar merata tanpa pola distribusi khusus. Selain itu, terdapat fitur seperti `StandardHours` yang tidak memiliki variasi sama sekali, sehingga kemungkinan tidak memberikan kontribusi informasi dalam proses pemodelan selanjutnya.

### **Analisis Hubungan Fitur Numerik terhadap target**

Menggunakan visualisasi, kita dapat melihat hubungan fitur numerik terhadap `Attrition`
"""

plt.figure(figsize=(8, 5))
sns.boxplot(data=df, x='Attrition', y='Age', palette="Set2")
plt.title("Distribusi Usia Berdasarkan Attrition")
plt.show()

plt.figure(figsize=(8, 5))
sns.boxplot(data=df, x='Attrition', y='MonthlyIncome', palette="Set2")
plt.title("Distribusi Pendapatan Bulanan Berdasarkan Attrition")
plt.show()

plt.figure(figsize=(8, 5))
sns.boxplot(data=df, x='Attrition', y='DistanceFromHome', palette="Set2")
plt.title("Distribusi Jarak dari Rumah Berdasarkan Attrition")
plt.show()

"""**Hasil Analisis Fitur Numerik**
  - Kolom `Age`: Karyawan dengan `Attrition` cenderung lebih muda dibandingkan karyawan yang tidak keluar.
  - Kolom `MonthlyIncome`: Karyawan dengan `Attrition` memiliki distribusi pendapatan yang lebih rendah dibandingkan karyawan yang bertahan.
  - `DistanceFromHome`: Tidak ada perbedaan signifikan dalam jarak rumah terhadap kantor antara karyawan yang keluar dan yang bertahan.

### **Distribusi YearsAtCompany dan TotalWorkingYears**

Menganalisis distribusi kolom `YearsAtCompany` dan `TotalWorkingYears` karena fitur ini relevan dalam memengaruhi `Attrition`
"""

plt.figure(figsize=(10, 6))
sns.histplot(data=df, x="YearsAtCompany", hue="Attrition", kde=True, palette="coolwarm", bins=30)
plt.title("Distribusi YearsAtCompany Berdasarkan Attrition")
plt.xlabel("YearsAtCompany")
plt.ylabel("Count")
plt.show()

plt.figure(figsize=(10, 6))
sns.histplot(data=df, x="TotalWorkingYears", hue="Attrition", kde=True, palette="coolwarm", bins=30)
plt.title("Distribusi TotalWorkingYears Berdasarkan Attrition")
plt.xlabel("TotalWorkingYears")
plt.ylabel("Count")
plt.show()

"""Berdasarkan distribusi kolom `YearsAtCompany` dan `TotalWorkingYears` terhadap `Attrition`:
1. `YearsAtCompany`:
  - Karyawan dengan masa kerja singkat (sekitar 0-5 tahun) memiliki risiko `Attrition` lebih tinggi.
  - Distribusi menunjukkan bahwa karyawan baru cenderung keluar lebih cepat.

2. `TotalWorkingYears`:
  - Karyawan dengan pengalaman kerja lebih sedikit (0-10 tahun) lebih sering keluar dibandingkan yang memiliki pengalaman kerja lebih panjang.
  - Ini menunjukkan pentingnya retensi awal karir dan pengembangan karyawan.

### **Analisis Interaksi Antar Fitur**

Bagian ini digunakan untuk melihat hubungan antara dua fitur utama dan bagaimana mereka berinteraksi dengan target `Attrition`
"""

plt.figure(figsize=(10, 6))
sns.scatterplot(data=df, x="MonthlyIncome", y="Age", hue="Attrition", style="OverTime", palette="coolwarm")
plt.title("Interaksi antara MonthlyIncome, Age, dan OverTime terhadap Attrition")
plt.xlabel("MonthlyIncome")
plt.ylabel("Age")
plt.legend(title="Attrition and OverTime")
plt.show()

"""Grafik di atas menunjukkan hubungan antara kolom `MonthlyIncome`, `Age`, dan `Overtime` dengan `Attrition`.

1. `Attrition` dan `Overtime`

   * Karyawan yang sering lembur (ditandai dengan simbol \*) cenderung lebih sering mengalami attrition (ditandai dengan warna biru) dibandingkan dengan yang tidak lembur.
2. `Attrition` dan `MonthlyIncome`

   * Karyawan dengan pendapatan bulanan yang lebih rendah memiliki tingkat attrition yang lebih tinggi dibandingkan dengan karyawan yang berpendapatan lebih tinggi.
   * Hal ini terlihat dari kepadatan titik biru yang lebih banyak di sisi kiri grafik (pendapatan bulanan rendah).
3. `Attrition` dan `Age`

   * Karyawan yang lebih muda cenderung mengalami attrition lebih sering, terlihat dari konsentrasi titik oranye di bagian bawah grafik (usia rendah).
4. Interaksi Antara Ketiga Variabel

   * Karyawan yang muda, berpendapatan rendah, dan sering lembur memiliki kecenderungan attrition yang lebih tinggi.

### **Hubungan Fitur Kategorik terhadap Target**
"""

for feature in categorical:
    contingency_table = pd.crosstab(df[feature], df['Attrition'])
    contingency_table.div(contingency_table.sum(1), axis=0).plot(kind='bar', stacked=True, figsize=(8, 5))
    plt.title(f"Distribution of Attrition by {feature}")
    plt.ylabel("Proportion")
    plt.xlabel(feature)
    plt.legend(title="Attrition", loc="upper right")
    plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability
    plt.tight_layout()
    plt.show()

"""Dari stacked bar chart, beberapa insight yang kita diperoleh:
1. **OverTime**: Karyawan yang sering lembur (OverTime = Yes) memiliki proporsi attrition yang jauh lebih tinggi.
2. **MaritalStatus**: Karyawan single lebih rentan keluar dibandingkan yang sudah menikah atau bercerai.
3. **JobRole**: Beberapa peran, seperti **Sales Representative** dan **Laboratory Technician**, memiliki attrition yang tinggi.
4. **BusinessTravel**: Karyawan yang sering melakukan perjalanan bisnis memiliki risiko keluar lebih tinggi dibandingkan kategori lainnya.

### **Menggunakan Chi-Square Test**
"""

categorical = [feature for feature in categorical if feature != 'Attrition']

chi_square_results = []
for feature in categorical:
    # Membuat tabel kontingensi
    contingency_table = pd.crosstab(df[feature], df['Attrition'])
    chi2, p, dof, expected = chi2_contingency(contingency_table)
    chi_square_results.append({
        "Feature": feature,
        "Chi-Square Statistic": chi2,
        "p-value": p
    })

chi_square_df = pd.DataFrame(chi_square_results)
chi_square_df

"""**Hasil Chi-Square Test**

1. **Fitur Signifikan terhadap Attrition** (p-value < 0.05):

   * **`BusinessTravel`**: Karyawan dengan frekuensi perjalanan bisnis tertentu lebih cenderung mengalami attrition.
   * **`JobInvolvement`**: Karyawan yang terlibat lebih dalam pekerjaan mereka menunjukkan kecenderungan lebih tinggi untuk mengalami attrition.
   * **`JobRole`**: Peran pekerjaan tertentu memiliki hubungan yang sangat signifikan dengan risiko keluar karyawan.
   * **`JobSatisfaction`**: Karyawan dengan tingkat kepuasan kerja rendah lebih cenderung untuk keluar.
   * **`MaritalStatus`**: Status pernikahan memengaruhi kecenderungan karyawan untuk keluar, terutama pada mereka yang berstatus single.
   * **`OverTime`**: Karyawan yang sering lembur sangat cenderung mengalami attrition.
   * **`WorkLifeBalance`**: Karyawan yang merasa tidak seimbang antara pekerjaan dan kehidupan pribadi memiliki kecenderungan lebih tinggi untuk keluar.

2. **Fitur Tidak Signifikan** (p-value >= 0.05):

   * **`Department`**: Tidak ada hubungan signifikan antara departemen dan attrition.
   * **`Education`**: Tingkat pendidikan tidak memengaruhi attrition secara signifikan.
   * **`EducationField`**: Bidang pendidikan tidak menunjukkan pengaruh signifikan terhadap attrition.
   * **`Gender`**: Jenis kelamin tidak memengaruhi kecenderungan keluar karyawan.
   * **`PerformanceRating`**: Penilaian kinerja tidak memiliki hubungan signifikan dengan attrition.
   * **`RelationshipSatisfaction`**: Kepuasan hubungan kerja tidak memiliki pengaruh yang signifikan terhadap attrition.

## **Korelasi Antar Variabel**

### **Korelasi Variabel Numerik**
"""

correlation_matrix = df[numerical].corr()
correlation_matrix

plt.figure(figsize=(12, 8))
sns.heatmap(correlation_matrix, annot=True, cmap="coolwarm", fmt=".2f")
plt.title("Heatmap Korelasi Antar Variabel Numerik")
plt.show()

"""Fitur-fitur sudah divisualisasikan menggunakan heatmap. Diperoleh insight bahwa Fitur-fitur seperti `MonthlyIncome`, `TotalWorkingYears`, dan `YearsAtCompany` memiliki korelasi positif yang kuat (0.77)

### **Korelasi Variabel Kategorik**
"""

# Cramér's V for Categorical-Categorical Correlation
def cramers_v(confusion_matrix):
    chi2 = chi2_contingency(confusion_matrix)[0]
    n = confusion_matrix.sum()
    return np.sqrt(chi2 / (n * (min(confusion_matrix.shape) - 1)))

cramers_v_results = []
for i, feature1 in enumerate(categorical):
    for feature2 in categorical[i+1:]:
        confusion_matrix = pd.crosstab(df[feature1], df[feature2])
        cramers_v_score = cramers_v(confusion_matrix)
        cramers_v_results.append({
            "Feature 1": feature1,
            "Feature 2": feature2,
            "Cramér's V": cramers_v_score
        })

cramers_v_df = pd.DataFrame(cramers_v_results)
cramers_v_df

"""**Hasil Cramér's V (Hubungan Antar Variabel Kategorikal)**

1. **Hubungan Tinggi (Cramér's V > 0.3)**:
   - `BusinessTravel` dan `JobRole`: Ada hubungan moderat antara frekuensi perjalanan bisnis dengan jenis pekerjaan.
   - `Gender` dan `JobRole`: Ada hubungan moderat antara gender dan jenis pekerjaan.

2. **Hubungan Rendah (Cramér's V < 0.3)**:
   - Sebagian besar hubungan antar variabel kategorikal bersifat lemah, seperti hubungan antara `BusinessTravel` dengan `MaritalStatus`.

# **Data Preprocessing**

Karena ada beberapa fitur yang tidak berkontribusi atau memengaruhi tingkat pengunduran diri dalam dataset ini, seperti EmployeeID, fitur-fitur ini perlu dihapus
"""

df = df.drop('EmployeeId', axis=1)

"""## **Label Encoding**

Pada bagian ini akan dilakukan :
- Memisahkan fitur numerik dan kategorikal dalam dataset.
- Mengubah fitur kategorikal menjadi format numerik menggunakan Label Encoding agar bisa digunakan dalam model Machine Learning.
"""

numerical, categorical = [], []

for feature in df.columns:
    if df[feature].dtype != 'object':
        numerical.append(feature)
    else:
        categorical.append(feature)

le = LabelEncoder()
df[categorical] = df[categorical].apply(le.fit_transform)

"""## **Data Normalization**

Bagian berikut digunakan untuk melakukan normalisasi atau penskalaan pada fitur numerik dalam dataset menggunakan teknik Min-Max Scaling. Penskalaan ini penting untuk memastikan bahwa fitur numerik memiliki skala yang seragam
"""

scaler = MinMaxScaler()
df[numerical] = scaler.fit_transform(df[numerical])

df

"""### **Melakukan feature selection dengan RFE**"""

X = df.drop(['Attrition'], axis=1)
y = df['Attrition']

rfe_selector = RFE(estimator=RandomForestClassifier(), n_features_to_select=10, step=1)
rfe_selector = rfe_selector.fit(X, y)

# Select top features
selected_features = X.columns[rfe_selector.support_]
X_selected = X[selected_features]

X_selected

"""Terdapat 10 feature setelah dilakukan feature selection menggunakan RFE

## **Split Data**
"""

# Split the data into train and test data
X_train, X_test, y_train, y_test = train_test_split(
    X_selected, y, test_size=0.2,  random_state=2025, stratify=y)

print('X_train :', X_train.shape)
print('y_train :', y_train.shape)
print('X_test  :', X_test.shape)
print('y_test  :', y_test.shape)

"""Kode di atas digunakan untuk membagi dataset menjadi data pelatihan (train) dan data pengujian (test). Fungsi `train_test_split()` dari pustaka `sklearn.model_selection` digunakan untuk melakukan pemisahan ini, dengan parameter `test_size=0.2` yang berarti 20% dari data akan digunakan sebagai data pengujian dan 80% sisanya sebagai data pelatihan. Parameter `random_state=2025` memastikan bahwa pembagian data ini dapat direproduksi secara konsisten setiap kali kode dijalankan. Selain itu, dengan menggunakan `stratify=y`, pembagian data akan mempertahankan proporsi distribusi label pada variabel target `y` di kedua set data (train dan test), sehingga distribusi target tetap seimbang.

### **Lakukan SMOTE untuk menangani imbalance data**
"""

# Apply SMOTE to the training data
smote = SMOTE(random_state=2025)
X_train_res, y_train_res = smote.fit_resample(X_train, y_train)

"""# **Modeling**

Pada tahap ini akan dilakukan pemodelan menggunakan berbagai model classifier

### **Logistic Regression**
"""

logistic_model = LogisticRegression(random_state=42, max_iter=1000)
logistic_model.fit(X_train_res, y_train_res)

y_pred_logistic = logistic_model.predict(X_test)

"""### **Random Forest**"""

rf_model = RandomForestClassifier(random_state=42, n_estimators=100)
rf_model.fit(X_train_res, y_train_res)

y_pred_rf = rf_model.predict(X_test)

"""### **XGboost Classifier**"""

xgb_model = XGBClassifier(random_state=42, eval_metric='logloss')
xgb_model.fit(X_train_res, y_train_res)

y_pred_xgb = xgb_model.predict(X_test)

"""### **SVM**"""

svm_model = SVC(random_state=42, kernel='rbf')
svm_model.fit(X_train_res, y_train_res)

y_pred_svm = svm_model.predict(X_test)

"""# **Evaluation**"""

# Metrics for Logistic Regression
logistic_accuracy = accuracy_score(y_test, y_pred_logistic)
logistic_precision = precision_score(y_test, y_pred_logistic, average='weighted')
logistic_recall = recall_score(y_test, y_pred_logistic, average='weighted')
logistic_f1 = f1_score(y_test, y_pred_logistic, average='weighted')

# Metrics for Random Forest
rf_accuracy = accuracy_score(y_test, y_pred_rf)
rf_precision = precision_score(y_test, y_pred_rf, average='weighted')
rf_recall = recall_score(y_test, y_pred_rf, average='weighted')
rf_f1 = f1_score(y_test, y_pred_rf, average='weighted')

# Metrics for XGBoost
xgb_accuracy = accuracy_score(y_test, y_pred_xgb)
xgb_precision = precision_score(y_test, y_pred_xgb, average='weighted')
xgb_recall = recall_score(y_test, y_pred_xgb, average='weighted')
xgb_f1 = f1_score(y_test, y_pred_xgb, average='weighted')

# Metrics for SVM
svm_accuracy = accuracy_score(y_test, y_pred_svm)
svm_precision = precision_score(y_test, y_pred_svm, average='weighted')
svm_recall = recall_score(y_test, y_pred_svm, average='weighted')
svm_f1 = f1_score(y_test, y_pred_svm, average='weighted')

model_comparison = pd.DataFrame({
    "Model": ["Logistic Regression", "Random Forest", "XGBoost", "SVM"],
    "Accuracy": [logistic_accuracy, rf_accuracy, xgb_accuracy, svm_accuracy],
    "Precision": [logistic_precision, rf_precision, xgb_precision, svm_precision],
    "Recall": [logistic_recall, rf_recall, xgb_recall, svm_recall],
    "F1-Score": [logistic_f1, rf_f1, xgb_f1, svm_f1]
})

model_comparison

# Detailed Classification Reports
print("\nClassification Report: Logistic Regression")
print(classification_report(y_test, y_pred_logistic))

print("\nClassification Report: Random Forest")
print(classification_report(y_test, y_pred_rf))

print("\nClassification Report: XGBoost")
print(classification_report(y_test, y_pred_xgb))

print("\nClassification Report: SVM")
print(classification_report(y_test, y_pred_svm))

"""Dari hasil pemodelan tersebut, terpilih model Random Forest Classifier sebagai model terbaik

### **Analisis Feature Importance Machine Learning**
"""

# SHAP values untuk model RF
explainer = shap.TreeExplainer(rf_model)
shap_values = explainer.shap_values(X_test)

# Mengambil feature importance dari model Random Forest
feature_importances = rf_model.feature_importances_

# Membuat DataFrame untuk feature importance
importance_df = pd.DataFrame({
    'Feature': X_selected.columns,
    'Importance': feature_importances
}).sort_values(by='Importance', ascending=False)

# Visualisasi Feature Importance
plt.figure(figsize=(10, 6))
sns.barplot(x='Importance', y='Feature', data=importance_df, palette="viridis")
plt.title("Feature Importance dari Random Forest")
plt.xlabel("Importance")
plt.ylabel("Feature")
plt.show()

"""Dari analisis feature importance tersebut, terlihat bahwa 5 variabel yang paling berpengaruh adalah TotalWorkingYears, YearsAtCompany, Age, DailyRate, dan HourlyRate

# **Conclusion**

Proyek ini bertujuan untuk memahami faktor-faktor yang memengaruhi tingkat **attrition** (keluar) karyawan di perusahaan **Jaya Jaya Maju** dan membangun model prediktif untuk mengidentifikasi karyawan dengan risiko keluar tinggi. Berikut adalah temuan utama dan insight yang diperoleh:

#### **1. Faktor-Faktor Penyebab Attrition**
Berdasarkan analisis data dan model prediktif, berikut adalah faktor utama yang memengaruhi attrition:
1. **OverTime**:
   - Karyawan yang sering lembur (**OverTime = Yes**) memiliki risiko keluar yang jauh lebih tinggi dibandingkan yang tidak lembur.
   - Fitur ini adalah prediktor terkuat dalam model prediktif.
2. **MonthlyIncome**:
   - Pendapatan bulanan yang lebih rendah meningkatkan risiko keluar karyawan.
   - Fitur ini mencerminkan pentingnya kepuasan finansial dalam retensi karyawan.
3. **YearsAtCompany dan TotalWorkingYears**:
   - Masa kerja pendek baik di perusahaan maupun secara total adalah indikator risiko tinggi.
4. **Fitur Pendukung Lain**:
   - Fitur seperti **DistanceFromHome** dan **Age** memiliki kontribusi kecil, tetapi tetap relevan dalam memahami pola attrition.

#### **2. Model Prediktif Terbaik**
Model terbaik yang digunakan dalam proyek ini adalah **Random Forest**, dengan metrik performa sebagai berikut:
- **Accuracy**: 84.91%
- **Precision**: 83.44%
- **Recall**: 84.91%
- **F1-Score**: 83.89%
Model ini menunjukkan performa superior dibandingkan model lainnya seperti Logistic Regression, Random Forest, dan SVM.

#### **3. Feature Importance**
Dari analisis feature importance menggunakan model Random Forest :
- **TotalWorkingYears** adalah fitur dengan kontribusi terbesar terhadap prediksi.
- **YearsAtCompany** dan **Age** juga memiliki peran penting.

---

### **Jawaban terhadap Pertanyaan Bisnis**
1. **Apa faktor utama yang memengaruhi attrition?**
   - Faktor utama adalah **OverTime**, **MonthlyIncome**, dan **YearsAtCompany**.
2. **Bagaimana tingkat kepuasan karyawan memengaruhi attrition?**
   - Fitur seperti **JobSatisfaction** tidak signifikan dalam model prediktif, tetapi tetap relevan secara deskriptif.
3. **Apa pola perilaku karyawan dengan risiko keluar tinggi?**
   - Karyawan yang lembur berlebihan, memiliki pendapatan rendah, dan masa kerja pendek cenderung memiliki risiko tinggi.
4. **Apakah kita memiliki alat bantu untuk memantau attrition?**
   - Model prediktif dan visualisasi hasil dapat digunakan untuk membangun dashboard interaktif untuk monitoring risiko.

---

### **Karakteristik Umum Karyawan yang Melakukan Attrition**
Berdasarkan analisis data, berikut adalah karakteristik umum karyawan yang melakukan attrition:
1. **Demografis**:
  - **Usia**: Rata-rata usia karyawan yang keluar adalah 30-an tahun.
  - **Jenis Kelamin**: Mayoritas adalah pria (Male).
  - **Status Pernikahan**: Sebagian besar karyawan yang keluar adalah Single, diikuti oleh Married.
2. **Pekerjaan dan Departemen**:
  - **Peran Kerja**: Posisi yang paling sering melakukan attrition adalah Laboratory Technician.
  - **Departemen**: Departemen **Research & Development** memiliki tingkat attrition tertinggi.
3. **Faktor Finansial dan Beban Kerja**:
  - **Pendapatan**: Rata-rata pendapatan bulanan karyawan yang keluar adalah 4,872.
  - **Lembur (OverTime)**: Sebagian besar karyawan yang keluar bekerja lembur secara signifikan.
4. **Kepuasan dan Keseimbangan**:
  - **Kepuasan Kerja**: Rata-rata tingkat kepuasan kerja adalah **2.5** (Medium).
  - **Keseimbangan Kerja-Hidup**: Rata-rata berada di tingkat **2.67** (Moderate).
5. **Masa Kerja**:
  - **Masa Kerja di Perusahaan**: Rata-rata masa kerja adalah **5 tahun**, dengan beberapa karyawan memiliki masa kerja sangat panjang hingga 40 tahun.

---

### **Rekomendasi Action Items untuk Perusahaan**
1. **Kurangi Lembur Berlebihan**:
   - Berikan program kerja fleksibel untuk meningkatkan keseimbangan kerja-hidup.
2. **Kaji Skala Gaji**:
   - Sesuaikan gaji karyawan agar kompetitif di pasar dan berikan insentif tambahan.
3. **Perkuat Retensi Karyawan Baru**:
   - Implementasikan program onboarding dan mentoring untuk karyawan dengan masa kerja pendek.
4. Mengidentifikasi karyawan dengan YearsAtCompany dan TotalWorkingYears yang pendek, lalu memberikan perhatian khusus terhadap pengembangan karier dan kepuasan mereka.
5. Menciptakan lingkungan kerja yang lebih inklusif dan mendukung bagi karyawan dari berbagai kelompok usia.
6. **Gunakan Model Prediktif**:
   - Integrasikan model Random Forest untuk memonitor risiko secara real-time melalui dashboard HR.

# **Model Export**
"""

from google.colab import drive
drive.mount('/content/drive')

joblib.dump(rf_model, '/content/drive/MyDrive/Laskar AI/Submission Penerapan Data Science 1/rf_model.joblib')